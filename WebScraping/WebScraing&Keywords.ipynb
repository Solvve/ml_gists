{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WebScraing&Keywords.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**Installing Packages and Importing Libraries**"
      ],
      "metadata": {
        "id": "rlIcEI_KRHpX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC-98bV5O9rp",
        "outputId": "c75d95f1-337e-4714-c281-d2c81d62e0b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (4.6.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IiYCD31QDy_",
        "outputId": "33fbc208-eedc-4d7c-8f8b-a241bd97a1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests) (2021.10.8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keybert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdoVWkuMe3nT",
        "outputId": "d1a731ec-0e62-43dd-e8df-a0a3ee470f7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keybert\n",
            "  Downloading keybert-0.5.1.tar.gz (19 kB)\n",
            "Collecting sentence-transformers>=0.3.8\n",
            "  Downloading sentence-transformers-2.2.0.tar.gz (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from keybert) (1.21.5)\n",
            "Collecting rich>=10.4.0\n",
            "  Downloading rich-12.1.0-py3-none-any.whl (229 kB)\n",
            "\u001b[K     |████████████████████████████████| 229 kB 11.8 MB/s \n",
            "\u001b[?25hCollecting commonmark<0.10.0,>=0.9.0\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions<5.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (3.10.0.2)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich>=10.4.0->keybert) (2.6.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.2->keybert) (1.4.1)\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (4.63.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (0.11.1+cu111)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.3.8->keybert) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 52.9 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.3 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 47.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2019.12.20)\n",
            "Collecting tokenizers!=0.11.3,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 33.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (4.11.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.7.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers>=0.3.8->keybert) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (1.24.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (7.1.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (7.1.2)\n",
            "Building wheels for collected packages: keybert, sentence-transformers\n",
            "  Building wheel for keybert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keybert: filename=keybert-0.5.1-py3-none-any.whl size=21332 sha256=0a9f54c10a8de21be07c955319af5649b19b1ac6978107c63c3aa543c59ae9fd\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/95/c5/f5ceed2a9f9e80bc1a706a10a6fb03d726df7a3dd11800a58b\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.0-py3-none-any.whl size=120747 sha256=5c41896f2ad68ea536b64fadf07098c38383aab9408ae22121b7b397aa746321\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/c0/df/b6873ab7aac3f2465aa9144b6b4c41c4391cfecc027c8b07e7\n",
            "Successfully built keybert sentence-transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, commonmark, sentence-transformers, rich, keybert\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed commonmark-0.9.1 huggingface-hub-0.4.0 keybert-0.5.1 pyyaml-6.0 rich-12.1.0 sacremoses-0.0.49 sentence-transformers-2.2.0 sentencepiece-0.1.96 tokenizers-0.11.6 transformers-4.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Sr61-RZnC8s",
        "outputId": "010fa4e9-92eb-4352-be9a-c20744f931b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting yake\n",
            "  Downloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▌                          | 10 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 20 kB 18.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 30 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 40 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 60 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from yake) (2.6.3)\n",
            "Collecting jellyfish\n",
            "  Downloading jellyfish-0.9.0.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 10.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=6.0 in /usr/local/lib/python3.7/dist-packages (from yake) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from yake) (0.8.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from yake) (1.21.5)\n",
            "Collecting segtok\n",
            "  Downloading segtok-1.5.11-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from segtok->yake) (2019.12.20)\n",
            "Building wheels for collected packages: jellyfish\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.9.0-cp37-cp37m-linux_x86_64.whl size=73974 sha256=6803cb9317b1f5bf1ef8a48f42b51e9464a87f3460e415e5512ce9e3697f7db8\n",
            "  Stored in directory: /root/.cache/pip/wheels/fe/99/4e/646ce766df0d070b0ef04db27aa11543e2767fda3075aec31b\n",
            "Successfully built jellyfish\n",
            "Installing collected packages: segtok, jellyfish, yake\n",
            "Successfully installed jellyfish-0.9.0 segtok-1.5.11 yake-0.4.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rake_nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kaw0yqI4x-oy",
        "outputId": "ed0daa1b-3966-412c-e823-82492aed1dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rake_nltk\n",
            "  Downloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\n",
            "Collecting nltk<4.0.0,>=3.6.2\n",
            "  Downloading nltk-3.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.63.0)\n",
            "Collecting regex>=2021.8.3\n",
            "  Downloading regex-2022.3.15-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 14.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (7.1.2)\n",
            "Installing collected packages: regex, nltk, rake-nltk\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nltk-3.7 rake-nltk-1.0.6 regex-2022.3.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import yake\n",
        "from operator import itemgetter\n",
        "from rake_nltk import Rake\n",
        "import nltk\n",
        "from gensim.summarization import keywords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIGcZiUPm-Fg",
        "outputId": "9325e295-1646-4924-a5e4-998873a829b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request, sys, time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import date\n",
        "import numpy as np\n",
        "from keybert import KeyBERT"
      ],
      "metadata": {
        "id": "0kfp_Wl3QIyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Web Scraping**"
      ],
      "metadata": {
        "id": "krfMcyNiRMl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "today = date.today()\n",
        "d = today.strftime(\"%m-%d-%y\")\n",
        "print(\"date =\" ,d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW2jV8lYRUdZ",
        "outputId": "81a4066a-8a63-42aa-8447-9272f4faa53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date = 04-05-22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nbc_business = \"https://www.nbcnews.com/business\"\n",
        "res = requests.get(nbc_business)\n",
        "soup = BeautifulSoup(res.content, 'html.parser')"
      ],
      "metadata": {
        "id": "pxlHY2U2T6mk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headlines = soup.find_all('span',{'class':'tease-card__headline'})\n",
        "data_nbc = pd.DataFrame(headlines)"
      ],
      "metadata": {
        "id": "UcedYE_hUT_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://www.nbcnews.com/business\"\n",
        "r1 = requests.get(url)\n",
        "coverpage = r1.content\n",
        "soup1 = BeautifulSoup(coverpage, 'html5lib')\n",
        "coverpage_news = soup1.find_all('h2',{'class':'tease-card__headline'})"
      ],
      "metadata": {
        "id": "DKOImjq1XucJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coverpage_news[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPwA2kKDYPJP",
        "outputId": "3add1f4c-9a37-4673-f11d-569bd9bac30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<h2 class=\"tease-card__headline tease-card__title tease-card__title--news relative\"><a href=\"https://www.nbcnews.com/politics/white-house/biden-highlight-administrations-efforts-boost-trucking-jobs-rcna22799\"><span class=\"tease-card__headline\">Biden highlights administration's efforts to boost trucking jobs</span></a><span class=\"\"></span></h2>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "link = coverpage_news[4].find('a')['href']\n",
        "\n",
        "article = requests.get(link)\n",
        "article_content = article.content\n",
        "soup_article = BeautifulSoup(article_content, 'html5lib')\n",
        "body = soup_article.find_all('div', class_='article-body__content')\n",
        "# x = body.find_all('p')"
      ],
      "metadata": {
        "id": "oUYJEFkUg2ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article = requests.get('https://www.nbcnews.com/nightly-news/video/more-companies-shifting-to-four-day-workweeks-136899141567')"
      ],
      "metadata": {
        "id": "GGcj-K45hDay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scraping the first 10 articles\n",
        "number_of_articles = 10\n",
        "# Empty lists for content, links and titles\n",
        "news_contents = []\n",
        "list_links = []\n",
        "list_titles = []\n",
        "\n",
        "for n in np.arange(0, number_of_articles):\n",
        "    \n",
        "    # Getting the link of the article\n",
        "    link = coverpage_news[n].find('a')['href']\n",
        "    list_links.append(link)\n",
        "    \n",
        "    # Getting the title\n",
        "    title = coverpage_news[n].find('a').get_text()\n",
        "    list_titles.append(title)\n",
        "    \n",
        "    # Reading the content (it is divided in paragraphs)\n",
        "    article = requests.get(link)\n",
        "    article_content = article.content\n",
        "    soup_article = BeautifulSoup(article_content, 'html5lib')\n",
        "    body = soup_article.find_all('div', class_='article-body__content')\n",
        "    \n",
        "    if body:\n",
        "        x = body[0].find_all('p')\n",
        "    \n",
        "        # Unifying the paragraphs\n",
        "        list_paragraphs = []\n",
        "        for p in np.arange(0, len(x)):\n",
        "            paragraph = x[p].get_text()\n",
        "            list_paragraphs.append(paragraph)\n",
        "            final_article = \" \".join(list_paragraphs)\n",
        "            \n",
        "        news_contents.append([title, link, final_article])\n",
        "\n",
        "    else:\n",
        "      pass"
      ],
      "metadata": {
        "id": "VZuQDY7CWDBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "news_contents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGPf3aQNff7k",
        "outputId": "9a0d900e-7a60-4923-e4d5-9ebf4303206d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Burger King accused of false advertising in lawsuit alleging Whoppers are too small',\n",
              "  'https://www.nbcnews.com/business/consumer/burger-king-false-advertising-lawsuit-whopper-burgers-rcna22916',\n",
              "  'It\\'s not the kind of Whopper Burger King wants to be associated with. A South Florida lawyer has filed a federal lawsuit seeking class-action status alleging that Burger King has misled customers by portraying its food as being much larger compared with what it has served to customers in real life. The suit, brought by attorney Anthony Russo, alleges Burger King began inflating the size of its burgers in images around September 2017. Before that, the suit claims, Burger King \"more fairly\" advertised its food products. Today, the size of virtually every food item advertised by Burger King is \"materially overstated,\" the lawsuit says. Russo and the plaintiffs he is representing single out advertisements for Burger King’s trademark Whopper, saying the entire burger is 35 percent larger than the real-life version, with double the meat than what is actually served. The suit cites as witnesses multiple YouTube users who specialize in food reviews and Twitter users who complained about their orders.  It\\'s not the first time Burger King has been accused of inflating food in its ads. The United Kingdom\\'s advertising authority cited the company 12 years ago for burgers that had height and thickness \"considerably less\" than what was advertised. The suit, which seeks class-action status, demands monetary damages and a court order requiring Burger King to end what it says are its deceptive practices. Representatives for Burger King and its parent company, Restaurant Brands International, didn’t immediately respond to an emailed request for comment. Jonathan Maze, the editor in chief of Restaurant Business magazine, said that while lawsuits against fast-food companies like Russo\\'s may seem to lack merit, they can sometimes scare company executives into paying settlements \"when they fear bad publicity.\"  In 2020, a California judge approved\\xa0a $6.5 million settlement in a class-action lawsuit filed against Chipotle over what was alleged to be a misleading non-GMO advertising campaign. \"Big or small, justice is justice, and laws are laws,\" Russo said, \"and just because something happens to appear in someone’s opinion to be minor doesn’t mean that it is.\"  He said he was seeking greater transparency in industry advertising more broadly. \"If I’m advertising a vehicle, you don’t Photoshop it to enhance it,\" he said. \"Sure, maybe you shoot it in its best light, but certainly you don’t make it misleading. That’s really the basis for these kinds of lawsuits.\"'],\n",
              " [\"Biden highlights administration's efforts to boost trucking jobs\",\n",
              "  'https://www.nbcnews.com/politics/white-house/biden-highlight-administrations-efforts-boost-trucking-jobs-rcna22799',\n",
              "  'WASHINGTON — President Joe Biden on Monday highlighted gains in the trucking industry since he took office and said his administration will continue to remove obstacles in the sector in an effort to help improve U.S. supply chains. Biden said last year was the best on record for trucking job growth since 1994, with gains continuing into the first quarter of 2022 after the administration unveiled its plan to boost trucking employment in December. The U.S. at the beginning of this year had its best three-month stretch for long-distance trucking hiring since the 1990s, the president said. \"We’ve got to keep it going, we’re building a better economy around American manufacturing and American supply chains,\" Biden said while flanked by semitrucks during an event on the White House lawn. \"You make it run, you literally make it run,\" Biden said to the group of truckers and industry officials on hand. \"I have nothing against investment bankers, but they could all retire and nothing much would change. You all quit, everything comes to a halt — think about it. I\\'m not joking, comes to a literal halt.\" Biden said his administration will continue to expedite the issuing of commercial driver\\'s licenses required to operate trucks. The White House said since January 2021, states have issued more than 876,000 of the special licenses, and trucking employment now exceeds pre-pandemic levels by 35,000 jobs. The administration has also made it a priority to hire more military veterans and women into the industry, which is dominated by men. As part of the plan, the industry has partnered with major veterans\\' organizations \"to support the recruitment and retention of veterans and military family members in trucking,\" the White House said. \"Trucking moves 72 percent of goods in America and is a lynchpin in our goods movement supply chain,\" the White House said in preview of the progress report. \"Trucking costs grew more than 20 percent last year as a surge in demand for goods caused by the pandemic confronted a decline in trucking employment that preceded the pandemic. The low supply of drivers is driven by high turnover and low job quality.\" To improve retention and prevent fast turnover in the trucking industry, the administration has nearly doubled apprenticeship programs for trucking through 100 employers and seven trade associations, the White House said. It also held multiple listening sessions with truck drivers, advocates and unions to understand how to make trucking jobs more appealing and high-quality. Biden has attributed historically high levels of inflation over the past year to pandemic-related supply chain disruptions, including worker shortages in the trucking industry. In December, the president announced a Trucking Action Plan to try to encourage more people to seek employment in the industry, a sector that has struggled for years to hire and retain workers. The plan is part of a joint effort by the Department of Transportation and Department of Labor and stems from the infrastructure legislation that Congress passed and Biden signed into law last year.'],\n",
              " ['Elon Musk buys 9 percent stake in Twitter',\n",
              "  'https://www.nbcnews.com/tech/tech-news/elon-musk-takes-9-percent-stake-twitter-slamming-companys-free-speech-rcna22805',\n",
              "  'One of Twitter\\'s loudest critics and most prominent users is now one of its biggest shareholders. Tesla CEO Elon Musk has bought up about 9.2 percent of Twitter, according to a regulatory filing Monday that detailed his stock purchases.  The stock-buying revelation comes as Musk emerges as one of the loudest and most prominent critics of Twitter\\'s moderation efforts, which in recent years have cracked down on everything from harassment and death threats to misinformation and conspiracy theories. News of Musk’s move sparked some hope among conservatives who have been critical of Twitter\\'s enforcement of its rules and its ban on former President Donald Trump.  Musk, who the Bloomberg Billionaire Index lists as the world\\'s richest person with a net worth of about $273 billion, has in recent months said on Twitter — where he comments regularly — that he had given \"serious thought\" to building a competitor to the company. He said in a post last month that given that the social media platform \"serves as the de facto public town square, failing to adhere to free speech principles fundamentally undermines democracy.\" Musk’s stake in Twitter is considered a passive investment, which means he is a long-term investor who\\'s looking to minimize his buying and selling of shares. But the sizable stake, along with Musk\\'s recent comments, indicate that he could be looking to exert some control of the company.  “We would expect this passive stake as just the start of broader conversations with the Twitter board/management that could ultimately lead to an active stake and a potential more aggressive ownership role of Twitter,” Dan Ives of WedBush Securities wrote in a client note early Monday. Musk\\'s first tweet since the news broke Monday offered a bit of levity to the situation: Twitter’s stock surged more than 25 percent before the market opened Monday, while shares of Tesla rose slightly. Musk has clashed with regulators about his use of Twitter. Last month, Musk asked a federal judge to nullify a subpoena from securities regulators and throw out a 2018 court agreement in which he had to have someone pre-approve his posts on Twitter. At the time, U.S. securities regulators said they had legal authority to subpoena Tesla and Musk about his tweets, and that Musk’s move to throw out a 2018 court agreement that his tweets be pre-approved is not valid. Musk\\'s criticism of Twitter — happening almost exclusively on Twitter — has been mounting. In late march, he tweeted a poll asking people if they thought Twitter \"rigorously adheres\" to free speech principles. About 70 percent of the more than 2 million votes tallied said \"No.\" \"The consequences of this poll will be important. Please vote carefully,\" Musk added. If Musk does decide to try to exert influence on Twitter, it would be the second activist shareholder push on the company in just a few years.  Elliott Management, an investment firm known for taking large stakes in companies and pushing for management changes, took a sizable stake in Twitter in early 2020 and pushed for then-CEO Jack Dorsey to step down. Dorsey was able to strike a deal with Elliott Management that allowed him to say for the time being.  Dorsey stepped down as CEO in November, though he remains on the company\\'s board of directors.'],\n",
              " ['Disney-branded hand sanitizers recalled after carcinogens found',\n",
              "  'https://www.nbcnews.com/business/consumer/disney-branded-hand-sanitizers-recalled-carcinogens-found-rcna22854',\n",
              "  'Two Disney-branded hand sanitizer formulas are being recalled after they were found to contain carcinogens. Food and Drug Administration testing found that the products, a Mandalorian branded hand sanitizer and a Mickey Mouse branded one, contained benzene and methanol, respectively. Sales of the products, produced by a third-party manufacturer and imported by the Disney vendor Best Brands Consumer Products Inc., had already been paused last April for unrelated commercial reasons. Best Brands did not immediately respond to a request for comment. The company has said it has not received any reports of adverse events related to the two voluntarily recalled quantities of sanitizer to date, nor for any other finished product lots of its ethyl alcohol 68 percent hand sanitizer products.'],\n",
              " [\"Magic no more? DeSantis questions Disney's special operating city in Florida \",\n",
              "  'https://www.nbcnews.com/business/consumer/reedy-creek-disney-world-special-district-history-desantis-rcna22551',\n",
              "  'MIAMI — Imagine if Disney had to go through its local planning and zoning board to build a new castle. Or if it suddenly had to rely on Orange County, Florida, and other local jurisdictions to pick up its trash. Or if it could no longer sell its own bonds to build roads in its parks.  That\\'s what could happen if some Florida legislators get their way. On March 30, Spencer Roach, a member of Florida\\'s House of Representatives who represents State House District 79, tweeted that he and other legislators were continuing to discuss repealing a special legislative act that created the Reedy Creek Improvement District. It\\'s the unique zone — believed to be among the only example of its kind in the U.S. — in which Disney\\'s largest theme park and resort operates in the Sunshine State. The discussions came in response to Disney’s new opposition to Florida House Bill 1557, dubbed the “Don’t Say Gay” bill by critics, which restricts the teaching of sexual orientation or gender identity. When asked about the unique arrangement during a public appearance on Thursday, Florida Gov. Ron DeSantis indicated Disney had long received special treatment that it may no longer merit. “Someone said Disney has all these special perks,\" DeSantis said.  \"Should you retaliate against them for them coming out and demagoguing this bill? I don’t believe you \\'retaliate,\\' but I think what I would say is, as a matter of first principle, I don’t support special privileges in law just because a company is powerful, and they’ve been able to wield a lot of power.\" Florida\\'s legislature is not currently in session, so any measures taken would require a special convening, something Florida\\'s House and Senate leaders have not yet indicated is coming.  In an interview Friday afternoon, state Rep. Roach called Reedy Creek  \"the largest tax evasion scam in Florida history, if not U.S. history — and we’ve had our share of scams in Florida.\" \"They have an advantage,\" Roach continued, \" and it\\'s anti-economic liberty. That is my bent here. Really, the fundamental question  should be: Why did we do this in the first place? As Floridians, do we believe in free markets or not? If we do, then this is wrong.\" Disney did not immediately respond to an emailed request for comment. So what exactly is the Reedy Creek Improvement District, and what does it allow Disney to do? As founder Walter E. Disney was looking to set up his second theme park and resort in the mid-1960s, he began lobbying the state of Florida to grant his company an entire jurisdiction that would function as the equivalent of a county government but retain its own special rules.   In 1967, the Florida legislature created the Reedy Creek Improvement District. This governmental district, controlling approximately 25,000 acres, would be responsible for paying the cost of municipal services, including power, fire protection, water, waste management and roads.  Day-to-day operations are conducted separately from Disney, but the company, as Reedy Creek\\'s largest landowner, effectively controls the district\\'s Board of Supervisors.   The establishment of Reedy Creek frees Disney from asking a local planning commission for approval to build new structures or pay governmental impact fees when it builds new structures.  \"You can sympathize with that desire,\" said Richard Fogelsong, a retired political science professor at Rollins College in Winter Park, Florida, and the author of\\xa0\"Married to the Mouse: Walt Disney World and Orlando,\" a book about the creation of Walt Disney World. \"They wanted to build things like a 500-foot fiberglass palace castle — and there\\'s no clause in the local code for something like that.\"   But most important is Reedy Creek\\'s ability to collect taxes and issue bonds. For the current fiscal year, the district has a budget of more than $169 million — more than 90 percent of which comes from the collection of property taxes on Disney\\'s real estate.  That means it can avoid the headaches of local government that often come with asking residents to pay taxes to fund infrastructure.  \"It\\'s allowed them to create the typical municipal-type services at a level Disney wanted for its properties,\" said Tom Wilkes, an Orlando-based attorney with GrayRobinson who has worked on matters involving Reedy Creek. \"For instance, the roads are generally a notch or two higher than outside the district.\" As a result, Reedy Creek currently maintains an AA bond rating from Fitch, one of the biggest credit-rating agencies in the U.S., which notes Disney holds large reserves and is able to maintain broad revenue-raising powers, ensuring high financial flexibility. It is not clear what the ultimate impact on Disney\\'s bottom line would be if Reedy Creek were to be dissolved, Wilkes said. If anything, it could end up costing area taxpayers more if local governments had to begin servicing Disney parks, he said, noting that Disney pays property taxes to Orange and Osceola counties.  \"Disney pays its way when it comes to government services,\" Wilkes said. \"It pays the two counties, and two county school boards — and gets very little services in return. It doesn\\'t get any exemptions there.\" This is not the first time Florida officials have challenged Reedy Creek\\'s status; in the past, Disney has agreed to pay as much as $13 million in exchange for maintaining the district. As one Orange County lawmaker put it in the 1980s: “Without question, Disney is the largest taxpayer in Orange County. Without question, Disney is the largest employer in Orange County. And without question, Disney causes some of the greatest impact in Orange County.” Roach, the lawmaker who represents the state\\'s 79th House District, said barring a special legislative session, a bill could not be introduced to challenge Disney\\'s hold on Reedy Creek until 2023.  \"Right now it\\'s just an idea, though it\\'s not a new one, that I’m thinking about and have socialized with some colleagues,\" Roach said. He continued: \"Disney is politically vulnerable, and they’re in a position now where, if it\\'s politically possible to correct this aberration of the free market ... although it may on the surface look retaliatory, in politics, timing is important.\"  \"And if this is something we want to address, the time to do that is not when they\\'re untouchable, but when they\\'re politically vulnerable.\"'],\n",
              " ['Amazon workers in New York vote to unionize for the first time in company’s history',\n",
              "  'https://www.nbcnews.com/tech/workers-staten-island-vote-form-amazons-first-union-us-rcna22433',\n",
              "  'For the first time in Amazon’s 27-year history, a group of U.S.-based workers have voted to unionize.  Out of 4,785 ballots counted, 2,654 workers at a warehouse in Staten Island, New York, voted to join the Amazon Labor Union (ALU), which was formed independently by current and former employees of the tech giant.  The election is a major setback for the nation’s second-largest employer, which has invested heavily in thwarting union efforts in recent years. It is also a landmark victory for organized labor in the U.S., and comes at a moment when more Americans say they approve of unions than at any other time since 1965. Amazon employs roughly 1 million workers across the country and 1.6 million globally, according to its most recent earnings report. The National Labor Relations Board said that 67 ballots were still being contested. But that is not enough to change the outcome of the vote.  “I’m happy to share this experience with the workers I organized with since Day One,” Christopher Smalls, president of the Amazon Labor Union, said Thursday evening. Smalls was fired from Amazon in 2020 at the height of the first Covid wave in New York, after he helped organize a strike at the same Staten Island facility, called JFK8, demanding better health and safety protections. Smalls and his colleagues spent months stationed outside JFK8, hosting barbecues and encouraging Amazon workers to sign union authorization cards. The organizers said they were inspired by another labor organizing effort at an Amazon warehouse in Bessemer, Alabama, where the outcome of a repeat union election being counted this week is still unclear. As of Thursday evening, 38 percent of the mail-in ballots counted in Bessemer were in favor of joining the Retail, Wholesale and Department Store Union, or RWDSU, while 43 percent were against it. 416 of the total 2,284 ballots were still being challenged by either Amazon or the union. It may take days or weeks before the election is officially decided. “This is just the beginning and we will continue to fight,” said Stuart Appelbaum, president of RWDSU, during a video conference with reporters Thursday. “We believe that every valid vote must be counted and every objection heard.” Regardless of the final outcome, RWDSU has already fared much better in Bessemer than it did last April during the first union election at the warehouse, when it lost by a margin of more than 2-to-1. The National Labor Relations Board later ordered a new vote, after it found Amazon had violated labor law by interfering with the process. Only 39 percent of the more than 6,100 eligible workers at the Bessemer warehouse participated in the election, RWDSU said, down from 52 percent last year. Appelbaum noted that the annual turnover rate at Amazon is estimated to be around 150 percent, meaning many workers who participated in the last election may no longer work for the tech giant. In response to the union elections, Amazon spokesperson Richard Rocha said, “We’re disappointed with the outcome of the election in Staten Island because we believe having a direct relationship with the company is best for our employees. We’re evaluating our options, including filing objections based on the inappropriate and undue influence by the NLRB that we and others (including the National Retail Federation and U.S. Chamber of Commerce) witnessed in this election.” Amazon poured extensive resources into fighting both union campaigns. The company has spent more than $4.2 million on labor consultants since March 2021, according to a Department of Labor filing first reported by The New York Times. On a website created for workers at JFK8, Amazon painted the union as inexperienced and said it doesn’t “believe the ALU will add value to our relationship or how we work together.” Amazon also held dozens of “captive audience” meetings in both Staten Island and Bessemer, which workers said the company used to go over anti-union talking points. “They say that the human relations people are the ones who are coming to educate their employees. But I’ve been in those meetings,” Jennifer Bates, a union organizer at the Bessemer facility, told reporters Thursday. “Those meetings are not education meetings. Those meetings are designed to manipulate and intimidate employees.” Amazon’s labor practices have caught the attention of Democratic lawmakers on the House Oversight Committee, who announced Thursday that they were opening an investigation into the company’s safety policies regarding natural disasters. Last year, six Amazon workers were killed during a tornado in Illinois. Amazon spokesperson Kelly Nantel said the company planned to respond to the lawmakers “in due course,” and was currently focused on supporting its employees and the families of those who died in the tornado. Amazon has previously said that it already offers competitive benefits and wages that start at $18 an hour on average, and respects the right of employees to decide whether to join a union. In December, as part of a settlement with the National Labor Relations Board, Amazon agreed to make it easier for workers to engage in labor organizing at its warehouses. A second Amazon facility in Staten Island, called LDJ5, will begin voting whether to join the ALU later this month. All three elections are part of a wider national labor organizing movement occurring at a number of U.S. companies, including Starbucks and the outdoor retailer REI. But overall union membership still declined last year, according to the Bureau of Labor Statistics. The organizing campaigns at Amazon’s U.S. facilities have also been a source of inspiration for the company’s international workers, some of which are already unionized. Employees in Japan and parts of Europe have cited the American efforts in their own campaigns. “I got emotional a few days ago because I actually thought about how, even if things didn’t move as fast in our area, across the country, nationally and internationally, people have gotten the courage because of what we stood up and did in Bessemer,” said Bates. “I’m ecstatic that everyone is making a move and they’re encouraged to fight back.”'],\n",
              " ['Will tapping the Strategic Petroleum Reserve lead to lower gas prices? ',\n",
              "  'https://www.nbcnews.com/business/oil-tapping-strategic-petroleum-reserve-lower-gas-prices-guide-rcna22484',\n",
              "  'In a move to lower gas prices, which continue to hover near the record high, President Joe Biden announced plans Thursday to release roughly 1 million barrels of oil a day from the Strategic Petroleum Reserve for about six months. The release would be the largest in the reserve’s nearly 50-year history. But it’s difficult to predict how effective it will be in relieving the pain at the pump.\\xa0\\xa0 Here’s what you need to know:\\xa0 What is the Strategic Petroleum Reserve? The reserve is the country’s emergency supply of oil. It’s housed underground in dozens of caverns among four salt domes along the coasts of Texas and Louisiana. The reserve can hold more than 700 million barrels to be used “to counter a disruption in commercial oil supplies which could threaten the U.S. economy,” according to the Energy Department. The oil can be sold to other countries and used to pump more supply into the market. Why was it created? The reserve was created by President Gerald Ford in 1975 in the aftermath of the Arab oil embargo, which damaged the U.S. economy. After the embargo was imposed in October 1973, the price of a barrel of oil quadrupled, gas prices spiked, and the U.S. faced its first fuel shortage since World War II.\\xa0 How quickly can oil from the reserve enter the market? Up to 4.4 million barrels of oil can be extracted from the reserve a day for a maximum of 90 days. Once the president calls for a release, it can take at least 13 days for the oil to go out for delivery, according to the Energy Department. The first barrels in the upcoming release are set to hit the market in May. Will releasing more oil onto the market bring down gas prices?\\xa0 “There’s no firm answer,” Biden said Thursday. “It could come down the better part of, you know, anything from 10 cents to 35 cents a gallon. It’s unknown at this point.” Biden said he’s waiting to see whether U.S. allies contribute to the release. “My guess is it could be as high — somewhere between 30 million to 50 million barrels. And the higher the number, the more likely the prices to come down.” Stewart Glickman, an energy analyst at CFRA Research, said tapping the reserve could produce a “small reduction in oil prices because of an increase in supply.” But he said he doesn’t expect it will be “that effective in pushing prices down.”\\xa0 “It might give you a little bit of short-term relief in the same way that taking some Advil will give you temporary relief from a headache,” he said. “But the root cause of the headache is probably still going to be there, and that’s going to be sticking around long after the medicine’s worn off.” Glickman pointed out that 1 million barrels accounts for just 5 percent of the daily oil consumption in the U.S. Last year, the U.S. consumed 19.78 million barrels of oil a day, according to the U.S. Energy Information Administration. So why not take out more? Glickman said that the reserve is intended to be a “buffer” and that reducing it too much could “limit our flexibility the next time we have some kind of unanticipated shock, like a hurricane.”\\xa0\\xa0 Has it been done before? The U.S. has tapped into the reserve numerous times, including in the aftermath of six hurricanes since 2002, among them Harvey and Katrina. Biden has called for multiple releases since he took office, including one in November, when 50 million barrels were released to stabilize the market. The last time reserve oil was used amid geopolitical tensions was in 1991 during the Gulf War. Some critics argue that Biden is misusing the reserve to gain political points, rather than respond to an emergency. Although Severin Borenstein, the faculty director of the Energy Institute at the Haas School of Business at the University of California, Berkeley, said “politically it’s probably happening because gas prices are high,” he said he believes “it is the right use of the reserve.” “The reserve was set up in the 1970s after the Arab oil embargo to defend against geopolitical disruptions in the oil market, which is exactly what’s going on right now with Russia’s invasion of Ukraine,” he said.'],\n",
              " ['New vehicles will need to travel 40 miles per gallon by 2026, new rule says',\n",
              "  'https://www.nbcnews.com/business/autos/new-vehicles-will-need-travel-40-miles-gallon-2026-new-rule-says-rcna22555',\n",
              "  'DETROIT — New vehicles sold in the United States will have to travel an average of at least 40 miles per gallon of gasoline in 2026 under new rules unveiled Friday by the government. The National Highway Traffic Safety Administration said its fuel economy requirements will undo a rollback of standards enacted under President Donald Trump. The new requirements increase gas mileage by 8 percent per year for model years 2024 and 2025 and 10 percent in the 2026 model year. For the current model year, standards enacted under Trump require the fleet of new vehicles to get just over 24 miles per gallon in real-world driving. Agency officials say the requirements are the maximum that the industry can achieve over the time period and will reduce gasoline consumption by more than 220 billion gallons over the life of vehicles, compared with the Trump standards. Trump’s administration rolled back fuel economy requirements so they rose 1.5 percent per year, which environmental groups said was inadequate to limit planet-warming greenhouse gas emissions that fuel climate change. But the new standards won’t immediately match those adopted through 2025 under President Barack Obama. NHTSA officials said they will equal the Obama standards by 2025 and slightly exceed them for the 2026 model year. The Obama-era standards automatically adjusted for changes in the type of vehicles people are buying. When they were enacted in 2012, 51 percent of new vehicle sales were cars and 49 percent SUVs and trucks. Last year, 77 percent of new vehicle sales were SUVs and trucks, which generally are less efficient than cars. Some environmental groups said the new requirements from NHTSA under President Joe Biden don’t go far enough to fight global warming. “Climate change has gotten much worse, but these rules only require automakers to reduce gas-guzzling slightly more than they agreed to cut nine years ago,” said Dan Becker, director of the Safe Climate Transport Center at the Center for Biological Diversity. He said the final rule is about 2 mpg short of the strongest alternative that NHTSA considered. Officials said that under the new standards, owners would save about $1,400 in gasoline costs during the lifetime of a 2029 model year vehicle. Carbon dioxide emissions would drop by 2.5 billion metric tons by 2050 under the standards, the NHTSA said. The agency did not give figures for how much the standards would increase the cost of vehicles. Auto dealers say more stringent requirements drive up prices and push people out of an already expensive new-car market. The NHTSA sets fuel economy requirements, while the Environmental Protection Agency develops limits on greenhouse gas emissions. NHTSA officials said their requirements nearly match rules adopted in December by the EPA, so automakers don’t have to comply with two rules.'],\n",
              " [\"House Oversight panel launches investigation into Amazon's labor practices\",\n",
              "  'https://www.nbcnews.com/politics/congress/house-oversight-panel-launches-investigation-amazons-labor-practices-rcna22509',\n",
              "  'A major investigative committee on Capitol Hill is launching a workplace safety probe into one of the nation’s biggest employers by demanding Amazon provide details on its labor practices. Three key Democrats on the House Oversight Committee — Chair Carolyn Maloney of New York, Rep. Cori Bush of Missouri and Rep. Alexandria Ocasio-Cortez of New York — sent a letter Thursday to Amazon\\'s president and CEO, requesting documents on the company’s labor policies and procedures, particularly during severe weather events. Tornadoes killed six workers last year at an Amazon distribution center in Edwardsville, Illinois. \"We are concerned by recent reports that Amazon may be putting the health and safety of its workers at risk, including by requiring them to work in dangerous conditions during tornadoes, hurricanes, and other extreme weather,\" the lawmakers wrote in a letter Thursday to Chief Executive Andy Jassy. “As one of our country’s largest and most profitable corporations, it is imperative that Amazon protect workers’ safety and refrain from practices that could put them in danger,” the lawmakers wrote. The tornado in Illinois prompted workers to ask questions about the company\\'s handling of emergency responses, with some suggesting Amazon was ill-prepared for the natural disaster and did little to train workers for those kinds of emergencies. In an effort to piece together what led up to the Edwardsville tragedy, the House panel is requesting documentation of attendance and leave policies, any emergency drills and communications before last year\\'s tornado regarding severe weather protocol and preparedness. At least five workers told NBC News in the aftermath of the deadly storm that their supervisors had warned employees they would be fired if they left their shifts early to find shelter. The family of one of the victims filed a wrongful death suit against Amazon in January. \"We also seek information about Amazon’s workplace policies or practices that may have prevented the workers from seeking safe shelter, as well as Amazon’s actions in responding to other severe weather incidents and natural disasters,\" the letter said. In a statement to NBC News, Amazon spokesperson Kelly Nantel said, \"Our focus continues to be on supporting our employees and partners, the families who lost loved ones, the surrounding community, and all those affected by the tornadoes. We will respond to this letter in due course.\" Lawmakers added that the probe \"will inform legislative efforts to curb unfair labor practices, strengthen protections for workers, and address the effects of climate change on worker safety.\" The letter also requested information on disciplinary actions taken against employees or contractors at facilities in seven locations related to reports detailing directives requiring Amazon employees to “stay on the job” during deadly wildfires in California in 2018, extreme heat in the Pacific Northwest last summer, and dangerous flooding during Hurricanes Irma in 2017 and Ida in 2021. The investigation comes at a challenging time for Amazon. The number of charges filed with the National Labor Relations Board accusing the company of interfering with workers’ right to organize more than tripled during the pandemic. Last February, New York Attorney General Letitia James sued Amazon over\\xa0allegations that it violated New York labor law, whistleblower protections and anti-retaliation laws. The lawsuit, filed in the Supreme Court of New York County, asserted that Amazon failed\\xa0to\\xa0provide adequate health and safety measures for employees at the company’s New York facilities. A company spokesperson said at the time that James\\' lawsuit did not present \"an accurate picture of Amazon’s industry-leading response to the pandemic.\" More recently, Amazon has been attempting to defeat efforts by workers to unionize in Alabama and New York.']]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_news = pd.DataFrame(news_contents, columns = ['Headline', 'Link', 'Content'])"
      ],
      "metadata": {
        "id": "LAyXl7GmgfID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Keyword Extraction**"
      ],
      "metadata": {
        "id": "29A57QRTmw5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "lTYbB904ia-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_news['Keywords_spaCy'] = df_news['Content'].apply(lambda x: (nlp(x)).ents)"
      ],
      "metadata": {
        "id": "SeefACfgijNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kw_extractor = yake.KeywordExtractor()\n",
        "language = \"en\"\n",
        "max_ngram_size = 6\n",
        "deduplication_threshold = 0.5\n",
        "numOfKeywords = 20\n",
        "custom_kw_extractor = yake.KeywordExtractor(lan=language, n=max_ngram_size, dedupLim=deduplication_threshold, top=numOfKeywords, features=None)"
      ],
      "metadata": {
        "id": "SKLThJ_8n7d-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_news['Keywords_Yake'] = df_news['Content'].apply(lambda x: list(map(itemgetter(0), (custom_kw_extractor.extract_keywords(x)))))"
      ],
      "metadata": {
        "id": "ZQwV0l6gmQOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_news['Keywords_Yake'] = df_news['Content'].apply(lambda x: custom_kw_extractor.extract_keywords(x))"
      ],
      "metadata": {
        "id": "SOJW0gx0oW8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_news.iloc[0][4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIadv8lWoljD",
        "outputId": "8b1fadef-d4f3-4adc-8ec9-58b18cf77add"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('compared with what it has served', -25.59799528194712),\n",
              " ('Burger King', 0.0035816903986236447),\n",
              " ('kind of Whopper Burger King', 0.013164643699504328),\n",
              " ('King', 0.017893690330897313),\n",
              " ('alleges Burger King began inflating', 0.019957048317035216),\n",
              " ('Burger King ’s trademark Whopper', 0.02197264543576258),\n",
              " ('Burger King has misled customers', 0.022646310568552444),\n",
              " ('South Florida lawyer', 0.027576539201970084),\n",
              " ('food item advertised by Burger King', 0.03169795287629701),\n",
              " ('class-action status alleging that Burger King', 0.03269766594066106),\n",
              " ('advertisements for Burger King', 0.06164182876234564),\n",
              " ('court order requiring Burger King', 0.0636677496548081),\n",
              " ('brought by attorney Anthony Russo', 0.08219935813394658),\n",
              " ('food', 0.08554846315096706),\n",
              " ('Russo', 0.08745439497197707),\n",
              " ('alleging that Burger King has misled', 0.0889327698617066),\n",
              " ('suit', 0.10328370451670717),\n",
              " ('King began', 0.10458117568625158),\n",
              " ('King began inflating the size', 0.10774565847187),\n",
              " ('requiring Burger King to end', 0.10822956783053474)]"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = Rake()\n",
        "\n",
        "def rake_implement(x,r):\n",
        "     r.extract_keywords_from_text(x)\n",
        "     return r.get_ranked_phrases()\n",
        "     \n",
        "df_news['Keywords_Rake'] =df_news['Content'].apply(lambda x: rake_implement(x,r))"
      ],
      "metadata": {
        "id": "LVsphKyQye0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_news['Keywords_Gensim'] =df_news['Content'].apply(lambda x: keywords(x).replace('\\n', ', '))"
      ],
      "metadata": {
        "id": "3fTijJsZ2WbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kw_model = KeyBERT(model='all-mpnet-base-v2')"
      ],
      "metadata": {
        "id": "bkUKDQSJsn2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_news['Keywords_BERT'] = df_news['Content'].apply(lambda x: kw_model.extract_keywords(x, keyphrase_ngram_range=(3, 6), stop_words='english', highlight=False, top_n=10))"
      ],
      "metadata": {
        "id": "vtCCkMB1zMvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in df_news.loc[0][7]:\n",
        "  print(f'{item[0]}, ({(item[1]*100):.2f}%)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Qt_TyqyCe0S",
        "outputId": "eebb1c8d-e336-4176-c6f8-3ddc54a627fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alleges burger king began inflating size, (72.76%)\n",
            "burger king materially overstated lawsuit, (70.24%)\n",
            "burger king began inflating size burgers, (70.00%)\n",
            "burger king began inflating size, (69.56%)\n",
            "burger king materially overstated lawsuit says, (68.63%)\n",
            "september 2017 suit claims burger king, (67.82%)\n",
            "burger king trademark whopper, (67.37%)\n",
            "suit claims burger king, (67.37%)\n",
            "advertised burger king materially overstated lawsuit, (67.12%)\n",
            "2017 suit claims burger king, (66.76%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_news['BERT'] = df_news['Keywords_BERT'].apply(lambda x: list(f'{item[0]} ({(item[1]*100):.2f}%)' for item in x)).apply(lambda y: ' '.join(map(str, y)))"
      ],
      "metadata": {
        "id": "kRi5PB6g0Xzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_news['Yake'] = df_news['Keywords_Yake'].apply(lambda x: list(f'{item[0]} ({(item[1]*100):.2f}%)' for item in x)).apply(lambda y: ' '.join(map(str, y)))"
      ],
      "metadata": {
        "id": "xsPjNXeSEtND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_news['Rake'] =df_news['Keywords_Rake'].apply(lambda x: x[:15])"
      ],
      "metadata": {
        "id": "9mrTu2n-D9ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_news[['Headline', 'Link', 'Content', 'BERT']].copy()"
      ],
      "metadata": {
        "id": "9gCxcmrDQ0re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mzWthqmkQnzK",
        "outputId": "1ea783e0-8e09-4ded-baf4-9946b152495d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            Headline  \\\n",
              "0  Burger King accused of false advertising in la...   \n",
              "1  Biden highlights administration's efforts to b...   \n",
              "2          Elon Musk buys 9 percent stake in Twitter   \n",
              "3  Disney-branded hand sanitizers recalled after ...   \n",
              "4  Magic no more? DeSantis questions Disney's spe...   \n",
              "\n",
              "                                                Link  \\\n",
              "0  https://www.nbcnews.com/business/consumer/burg...   \n",
              "1  https://www.nbcnews.com/politics/white-house/b...   \n",
              "2  https://www.nbcnews.com/tech/tech-news/elon-mu...   \n",
              "3  https://www.nbcnews.com/business/consumer/disn...   \n",
              "4  https://www.nbcnews.com/business/consumer/reed...   \n",
              "\n",
              "                                             Content  \\\n",
              "0  It's not the kind of Whopper Burger King wants...   \n",
              "1  WASHINGTON — President Joe Biden on Monday hig...   \n",
              "2  One of Twitter's loudest critics and most prom...   \n",
              "3  Two Disney-branded hand sanitizer formulas are...   \n",
              "4  MIAMI — Imagine if Disney had to go through it...   \n",
              "\n",
              "                                                BERT  \n",
              "0  alleges burger king began inflating size (72.7...  \n",
              "1  president announced trucking (73.64%) trucking...  \n",
              "2  musk stake twitter considered passive investme...  \n",
              "3  disney branded hand sanitizer formulas recalle...  \n",
              "4  disney new opposition florida house 1557 (71.0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf615fbf-b28b-474d-a3ce-9dbfd50ec2c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Headline</th>\n",
              "      <th>Link</th>\n",
              "      <th>Content</th>\n",
              "      <th>BERT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Burger King accused of false advertising in la...</td>\n",
              "      <td>https://www.nbcnews.com/business/consumer/burg...</td>\n",
              "      <td>It's not the kind of Whopper Burger King wants...</td>\n",
              "      <td>alleges burger king began inflating size (72.7...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Biden highlights administration's efforts to b...</td>\n",
              "      <td>https://www.nbcnews.com/politics/white-house/b...</td>\n",
              "      <td>WASHINGTON — President Joe Biden on Monday hig...</td>\n",
              "      <td>president announced trucking (73.64%) trucking...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Elon Musk buys 9 percent stake in Twitter</td>\n",
              "      <td>https://www.nbcnews.com/tech/tech-news/elon-mu...</td>\n",
              "      <td>One of Twitter's loudest critics and most prom...</td>\n",
              "      <td>musk stake twitter considered passive investme...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Disney-branded hand sanitizers recalled after ...</td>\n",
              "      <td>https://www.nbcnews.com/business/consumer/disn...</td>\n",
              "      <td>Two Disney-branded hand sanitizer formulas are...</td>\n",
              "      <td>disney branded hand sanitizer formulas recalle...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Magic no more? DeSantis questions Disney's spe...</td>\n",
              "      <td>https://www.nbcnews.com/business/consumer/reed...</td>\n",
              "      <td>MIAMI — Imagine if Disney had to go through it...</td>\n",
              "      <td>disney new opposition florida house 1557 (71.0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf615fbf-b28b-474d-a3ce-9dbfd50ec2c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf615fbf-b28b-474d-a3ce-9dbfd50ec2c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf615fbf-b28b-474d-a3ce-9dbfd50ec2c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('NBCnews1.csv')"
      ],
      "metadata": {
        "id": "9SBfJijR3z_N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}